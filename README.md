# Group_10_Assignment_4_DataPipeline
GROUP 10 

GENERATING 100K USER DATA EACH  FOR CREATING DATA PIPELINE FOR TEN COMPANIES
This project implements an ETL (Extract, Transform, Load) pipeline for ingesting synthetic data into a PostgreSQL database for  fictional 10 companies, based in Ghana. The pipeline generates simulated customer data using the Faker library, creates a relational database schema, and loads the generated data into the database. Additionally, it provides functionality to query the data and save the queries into a file.

## Features

- Generates synthetic customer data including demographics, transaction activity, customer preferences, and communication methods.
- Ingests the generated data into a PostgreSQL database.
- Provides Python scripts to execute various data processing tasks and SQL queries.
- Dockerized for easy deployment and reproducibility.

## Prerequisites

- Python 3.0 +
- PostgreSQL
- psycopg2 library
- Docker (optional)

## Installation

1. Clone the repository:

```bash
git clone https://github.com/Data-Engineering-Training/Group_10_Assignment_4_DataPipeline.git

## More update to come
